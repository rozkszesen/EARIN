{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnDaAezyo-Lv"
      },
      "source": [
        "\n",
        "# **EARIN exercise 5: Artificial Neural Networks**\n",
        "\n",
        "Implementation of an N-layer perceptron for Iris classification\n",
        "\n",
        "Authors: *Julia Czmut*, *Laura Ploch*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mInIuD3_SPuZ"
      },
      "source": [
        "### Overview of the task\n",
        "\n",
        "The goal of this task is to implement an N-layer perceptron and verify how number of layers affects final metrics of Iris classification.\n",
        "\n",
        "The neural networks in our task are implemented with the help of Pytorch library, and they are all trained with the stochastic gradient descent optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHOPpOCxJW8G"
      },
      "source": [
        "## Dataset preprocessing\n",
        "\n",
        "The Iris dataset is first uploaded as raw data from *Iris.csv* file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSMe3vpxTTb_"
      },
      "source": [
        "Import modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "rEIPsgQ1l6DO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms4SRkyI0ASy"
      },
      "source": [
        "Upload the dataset source file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "DzsIIdSUrWVX",
        "outputId": "91352164-2882-4daf-9ad7-ad1a8944b379"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2c159fdf-3b9c-442c-8613-b0891d8b81ee\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2c159fdf-3b9c-442c-8613-b0891d8b81ee\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving Iris.csv to Iris.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCA3dufdUARM"
      },
      "source": [
        "### Preprocessing details\n",
        "\n",
        "The *IrisDataset* class stores our dataset and functions needed to prepare it. It inherits from the Pytorch *Dataset* class.\n",
        "\n",
        "The structure which stores the Iris dataset is the *data* list. When we first load the data from the .csv file (in *load_data()* function), we read each line and only save attributes which are needed. These are: sepal length, sepal width, petal length, petal width and species. The id is not necessary, so we leave it out.\n",
        "\n",
        "The species attribute contains categorical data, so we are using label encoding to encode it. Usually, one-hot encoding would be a better option for data which is not ordered, however the built-in *sklearn* Iris dataset used label encoding instead of one-hot encoding, so we also adopted this approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6wjPY_Z-B0X"
      },
      "source": [
        "**Splitting the dataset into features and labels**\n",
        "\n",
        "The next step of the dataset processing is splitting the dataset into X and Y for our classification task. It is done in *get_xy()* function of the IrisDataset class.\n",
        "\n",
        "**Features** (**X**) attributes: **sepal length**, **sepal width**, **petal length** and **petal width**.\n",
        "\n",
        "**Label** (**Y**) attribute which the models will predict: **species**. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KqP0s9ZhJZXx"
      },
      "outputs": [],
      "source": [
        "class IrisDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.data = []\n",
        "    self.load_data(\"Iris.csv\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.data[0][index], self.data[1][index]\n",
        "\n",
        "  def load_data(self, file_name=\"Iris.csv\"):\n",
        "    with open(\"Iris.csv\") as input_file:\n",
        "      csv_reader = csv.reader(input_file, delimiter=',')\n",
        "      next(csv_reader, None)\n",
        "\n",
        "      print(\"Loading data from Iris.csv...\")\n",
        "\n",
        "      iris_data = []\n",
        "\n",
        "      for line in csv_reader:\n",
        "        assert len(line) == 6\n",
        "        iris_record = []\n",
        "        # reading the numeric attributes (except from id which is unnecessary)\n",
        "        iris_record.append(float(line[1]))  # sepal length (cm)\n",
        "        iris_record.append(float(line[2]))  # sepal width (cm)\n",
        "        iris_record.append(float(line[3]))  # petal length (cm)\n",
        "        iris_record.append(float(line[4]))  # petal width (cm)\n",
        "    \n",
        "        # label encoding for the species attributes\n",
        "        species = line[5]\n",
        "        if species == \"Iris-setosa\":\n",
        "          species = 0\n",
        "        elif species == \"Iris-versicolor\":\n",
        "          species = 1\n",
        "        elif species == \"Iris-virginica\":\n",
        "          species = 2\n",
        "\n",
        "        iris_record.append(species)\n",
        "        iris_data.append(iris_record)\n",
        "\n",
        "      self.data = iris_data\n",
        "      print(\"Attributes before X-Y split:\")\n",
        "      print(self.data)\n",
        "      self.data = self.get_xy()\n",
        "\n",
        "  def get_xy(self):\n",
        "    X_train = []  # features\n",
        "    Y_train = []  # labels\n",
        "\n",
        "    for i in range(len(self.data)):\n",
        "      X_train.append(self.data[i][0:4])\n",
        "      Y_train.append(self.data[i][4])\n",
        "\n",
        "    return [X_train, Y_train]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74DdRCN5AqSS"
      },
      "source": [
        "**Initializing the dataset**\n",
        "\n",
        "Here we see the dataset before splitting it into features and labels, so simply a list of samples, where each sample is a 5-element attribute list, and then the dataset after the split, so a two element list [X, Y], where X is a list of lists of samples' features, and Y is a list of samples' labels (encoded species attribute)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Q4mxcKHv0Ja4",
        "outputId": "7805331e-2bcb-4432-cc2b-152276cae14d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from Iris.csv...\n",
            "Attributes before X-Y split:\n",
            "[[5.1, 3.5, 1.4, 0.2, 0], [4.9, 3.0, 1.4, 0.2, 0], [4.7, 3.2, 1.3, 0.2, 0], [4.6, 3.1, 1.5, 0.2, 0], [5.0, 3.6, 1.4, 0.2, 0], [5.4, 3.9, 1.7, 0.4, 0], [4.6, 3.4, 1.4, 0.3, 0], [5.0, 3.4, 1.5, 0.2, 0], [4.4, 2.9, 1.4, 0.2, 0], [4.9, 3.1, 1.5, 0.1, 0], [5.4, 3.7, 1.5, 0.2, 0], [4.8, 3.4, 1.6, 0.2, 0], [4.8, 3.0, 1.4, 0.1, 0], [4.3, 3.0, 1.1, 0.1, 0], [5.8, 4.0, 1.2, 0.2, 0], [5.7, 4.4, 1.5, 0.4, 0], [5.4, 3.9, 1.3, 0.4, 0], [5.1, 3.5, 1.4, 0.3, 0], [5.7, 3.8, 1.7, 0.3, 0], [5.1, 3.8, 1.5, 0.3, 0], [5.4, 3.4, 1.7, 0.2, 0], [5.1, 3.7, 1.5, 0.4, 0], [4.6, 3.6, 1.0, 0.2, 0], [5.1, 3.3, 1.7, 0.5, 0], [4.8, 3.4, 1.9, 0.2, 0], [5.0, 3.0, 1.6, 0.2, 0], [5.0, 3.4, 1.6, 0.4, 0], [5.2, 3.5, 1.5, 0.2, 0], [5.2, 3.4, 1.4, 0.2, 0], [4.7, 3.2, 1.6, 0.2, 0], [4.8, 3.1, 1.6, 0.2, 0], [5.4, 3.4, 1.5, 0.4, 0], [5.2, 4.1, 1.5, 0.1, 0], [5.5, 4.2, 1.4, 0.2, 0], [4.9, 3.1, 1.5, 0.1, 0], [5.0, 3.2, 1.2, 0.2, 0], [5.5, 3.5, 1.3, 0.2, 0], [4.9, 3.1, 1.5, 0.1, 0], [4.4, 3.0, 1.3, 0.2, 0], [5.1, 3.4, 1.5, 0.2, 0], [5.0, 3.5, 1.3, 0.3, 0], [4.5, 2.3, 1.3, 0.3, 0], [4.4, 3.2, 1.3, 0.2, 0], [5.0, 3.5, 1.6, 0.6, 0], [5.1, 3.8, 1.9, 0.4, 0], [4.8, 3.0, 1.4, 0.3, 0], [5.1, 3.8, 1.6, 0.2, 0], [4.6, 3.2, 1.4, 0.2, 0], [5.3, 3.7, 1.5, 0.2, 0], [5.0, 3.3, 1.4, 0.2, 0], [7.0, 3.2, 4.7, 1.4, 1], [6.4, 3.2, 4.5, 1.5, 1], [6.9, 3.1, 4.9, 1.5, 1], [5.5, 2.3, 4.0, 1.3, 1], [6.5, 2.8, 4.6, 1.5, 1], [5.7, 2.8, 4.5, 1.3, 1], [6.3, 3.3, 4.7, 1.6, 1], [4.9, 2.4, 3.3, 1.0, 1], [6.6, 2.9, 4.6, 1.3, 1], [5.2, 2.7, 3.9, 1.4, 1], [5.0, 2.0, 3.5, 1.0, 1], [5.9, 3.0, 4.2, 1.5, 1], [6.0, 2.2, 4.0, 1.0, 1], [6.1, 2.9, 4.7, 1.4, 1], [5.6, 2.9, 3.6, 1.3, 1], [6.7, 3.1, 4.4, 1.4, 1], [5.6, 3.0, 4.5, 1.5, 1], [5.8, 2.7, 4.1, 1.0, 1], [6.2, 2.2, 4.5, 1.5, 1], [5.6, 2.5, 3.9, 1.1, 1], [5.9, 3.2, 4.8, 1.8, 1], [6.1, 2.8, 4.0, 1.3, 1], [6.3, 2.5, 4.9, 1.5, 1], [6.1, 2.8, 4.7, 1.2, 1], [6.4, 2.9, 4.3, 1.3, 1], [6.6, 3.0, 4.4, 1.4, 1], [6.8, 2.8, 4.8, 1.4, 1], [6.7, 3.0, 5.0, 1.7, 1], [6.0, 2.9, 4.5, 1.5, 1], [5.7, 2.6, 3.5, 1.0, 1], [5.5, 2.4, 3.8, 1.1, 1], [5.5, 2.4, 3.7, 1.0, 1], [5.8, 2.7, 3.9, 1.2, 1], [6.0, 2.7, 5.1, 1.6, 1], [5.4, 3.0, 4.5, 1.5, 1], [6.0, 3.4, 4.5, 1.6, 1], [6.7, 3.1, 4.7, 1.5, 1], [6.3, 2.3, 4.4, 1.3, 1], [5.6, 3.0, 4.1, 1.3, 1], [5.5, 2.5, 4.0, 1.3, 1], [5.5, 2.6, 4.4, 1.2, 1], [6.1, 3.0, 4.6, 1.4, 1], [5.8, 2.6, 4.0, 1.2, 1], [5.0, 2.3, 3.3, 1.0, 1], [5.6, 2.7, 4.2, 1.3, 1], [5.7, 3.0, 4.2, 1.2, 1], [5.7, 2.9, 4.2, 1.3, 1], [6.2, 2.9, 4.3, 1.3, 1], [5.1, 2.5, 3.0, 1.1, 1], [5.7, 2.8, 4.1, 1.3, 1], [6.3, 3.3, 6.0, 2.5, 2], [5.8, 2.7, 5.1, 1.9, 2], [7.1, 3.0, 5.9, 2.1, 2], [6.3, 2.9, 5.6, 1.8, 2], [6.5, 3.0, 5.8, 2.2, 2], [7.6, 3.0, 6.6, 2.1, 2], [4.9, 2.5, 4.5, 1.7, 2], [7.3, 2.9, 6.3, 1.8, 2], [6.7, 2.5, 5.8, 1.8, 2], [7.2, 3.6, 6.1, 2.5, 2], [6.5, 3.2, 5.1, 2.0, 2], [6.4, 2.7, 5.3, 1.9, 2], [6.8, 3.0, 5.5, 2.1, 2], [5.7, 2.5, 5.0, 2.0, 2], [5.8, 2.8, 5.1, 2.4, 2], [6.4, 3.2, 5.3, 2.3, 2], [6.5, 3.0, 5.5, 1.8, 2], [7.7, 3.8, 6.7, 2.2, 2], [7.7, 2.6, 6.9, 2.3, 2], [6.0, 2.2, 5.0, 1.5, 2], [6.9, 3.2, 5.7, 2.3, 2], [5.6, 2.8, 4.9, 2.0, 2], [7.7, 2.8, 6.7, 2.0, 2], [6.3, 2.7, 4.9, 1.8, 2], [6.7, 3.3, 5.7, 2.1, 2], [7.2, 3.2, 6.0, 1.8, 2], [6.2, 2.8, 4.8, 1.8, 2], [6.1, 3.0, 4.9, 1.8, 2], [6.4, 2.8, 5.6, 2.1, 2], [7.2, 3.0, 5.8, 1.6, 2], [7.4, 2.8, 6.1, 1.9, 2], [7.9, 3.8, 6.4, 2.0, 2], [6.4, 2.8, 5.6, 2.2, 2], [6.3, 2.8, 5.1, 1.5, 2], [6.1, 2.6, 5.6, 1.4, 2], [7.7, 3.0, 6.1, 2.3, 2], [6.3, 3.4, 5.6, 2.4, 2], [6.4, 3.1, 5.5, 1.8, 2], [6.0, 3.0, 4.8, 1.8, 2], [6.9, 3.1, 5.4, 2.1, 2], [6.7, 3.1, 5.6, 2.4, 2], [6.9, 3.1, 5.1, 2.3, 2], [5.8, 2.7, 5.1, 1.9, 2], [6.8, 3.2, 5.9, 2.3, 2], [6.7, 3.3, 5.7, 2.5, 2], [6.7, 3.0, 5.2, 2.3, 2], [6.3, 2.5, 5.0, 1.9, 2], [6.5, 3.0, 5.2, 2.0, 2], [6.2, 3.4, 5.4, 2.3, 2], [5.9, 3.0, 5.1, 1.8, 2]]\n",
            "After X-Y split:\n",
            "[[[5.1, 3.5, 1.4, 0.2], [4.9, 3.0, 1.4, 0.2], [4.7, 3.2, 1.3, 0.2], [4.6, 3.1, 1.5, 0.2], [5.0, 3.6, 1.4, 0.2], [5.4, 3.9, 1.7, 0.4], [4.6, 3.4, 1.4, 0.3], [5.0, 3.4, 1.5, 0.2], [4.4, 2.9, 1.4, 0.2], [4.9, 3.1, 1.5, 0.1], [5.4, 3.7, 1.5, 0.2], [4.8, 3.4, 1.6, 0.2], [4.8, 3.0, 1.4, 0.1], [4.3, 3.0, 1.1, 0.1], [5.8, 4.0, 1.2, 0.2], [5.7, 4.4, 1.5, 0.4], [5.4, 3.9, 1.3, 0.4], [5.1, 3.5, 1.4, 0.3], [5.7, 3.8, 1.7, 0.3], [5.1, 3.8, 1.5, 0.3], [5.4, 3.4, 1.7, 0.2], [5.1, 3.7, 1.5, 0.4], [4.6, 3.6, 1.0, 0.2], [5.1, 3.3, 1.7, 0.5], [4.8, 3.4, 1.9, 0.2], [5.0, 3.0, 1.6, 0.2], [5.0, 3.4, 1.6, 0.4], [5.2, 3.5, 1.5, 0.2], [5.2, 3.4, 1.4, 0.2], [4.7, 3.2, 1.6, 0.2], [4.8, 3.1, 1.6, 0.2], [5.4, 3.4, 1.5, 0.4], [5.2, 4.1, 1.5, 0.1], [5.5, 4.2, 1.4, 0.2], [4.9, 3.1, 1.5, 0.1], [5.0, 3.2, 1.2, 0.2], [5.5, 3.5, 1.3, 0.2], [4.9, 3.1, 1.5, 0.1], [4.4, 3.0, 1.3, 0.2], [5.1, 3.4, 1.5, 0.2], [5.0, 3.5, 1.3, 0.3], [4.5, 2.3, 1.3, 0.3], [4.4, 3.2, 1.3, 0.2], [5.0, 3.5, 1.6, 0.6], [5.1, 3.8, 1.9, 0.4], [4.8, 3.0, 1.4, 0.3], [5.1, 3.8, 1.6, 0.2], [4.6, 3.2, 1.4, 0.2], [5.3, 3.7, 1.5, 0.2], [5.0, 3.3, 1.4, 0.2], [7.0, 3.2, 4.7, 1.4], [6.4, 3.2, 4.5, 1.5], [6.9, 3.1, 4.9, 1.5], [5.5, 2.3, 4.0, 1.3], [6.5, 2.8, 4.6, 1.5], [5.7, 2.8, 4.5, 1.3], [6.3, 3.3, 4.7, 1.6], [4.9, 2.4, 3.3, 1.0], [6.6, 2.9, 4.6, 1.3], [5.2, 2.7, 3.9, 1.4], [5.0, 2.0, 3.5, 1.0], [5.9, 3.0, 4.2, 1.5], [6.0, 2.2, 4.0, 1.0], [6.1, 2.9, 4.7, 1.4], [5.6, 2.9, 3.6, 1.3], [6.7, 3.1, 4.4, 1.4], [5.6, 3.0, 4.5, 1.5], [5.8, 2.7, 4.1, 1.0], [6.2, 2.2, 4.5, 1.5], [5.6, 2.5, 3.9, 1.1], [5.9, 3.2, 4.8, 1.8], [6.1, 2.8, 4.0, 1.3], [6.3, 2.5, 4.9, 1.5], [6.1, 2.8, 4.7, 1.2], [6.4, 2.9, 4.3, 1.3], [6.6, 3.0, 4.4, 1.4], [6.8, 2.8, 4.8, 1.4], [6.7, 3.0, 5.0, 1.7], [6.0, 2.9, 4.5, 1.5], [5.7, 2.6, 3.5, 1.0], [5.5, 2.4, 3.8, 1.1], [5.5, 2.4, 3.7, 1.0], [5.8, 2.7, 3.9, 1.2], [6.0, 2.7, 5.1, 1.6], [5.4, 3.0, 4.5, 1.5], [6.0, 3.4, 4.5, 1.6], [6.7, 3.1, 4.7, 1.5], [6.3, 2.3, 4.4, 1.3], [5.6, 3.0, 4.1, 1.3], [5.5, 2.5, 4.0, 1.3], [5.5, 2.6, 4.4, 1.2], [6.1, 3.0, 4.6, 1.4], [5.8, 2.6, 4.0, 1.2], [5.0, 2.3, 3.3, 1.0], [5.6, 2.7, 4.2, 1.3], [5.7, 3.0, 4.2, 1.2], [5.7, 2.9, 4.2, 1.3], [6.2, 2.9, 4.3, 1.3], [5.1, 2.5, 3.0, 1.1], [5.7, 2.8, 4.1, 1.3], [6.3, 3.3, 6.0, 2.5], [5.8, 2.7, 5.1, 1.9], [7.1, 3.0, 5.9, 2.1], [6.3, 2.9, 5.6, 1.8], [6.5, 3.0, 5.8, 2.2], [7.6, 3.0, 6.6, 2.1], [4.9, 2.5, 4.5, 1.7], [7.3, 2.9, 6.3, 1.8], [6.7, 2.5, 5.8, 1.8], [7.2, 3.6, 6.1, 2.5], [6.5, 3.2, 5.1, 2.0], [6.4, 2.7, 5.3, 1.9], [6.8, 3.0, 5.5, 2.1], [5.7, 2.5, 5.0, 2.0], [5.8, 2.8, 5.1, 2.4], [6.4, 3.2, 5.3, 2.3], [6.5, 3.0, 5.5, 1.8], [7.7, 3.8, 6.7, 2.2], [7.7, 2.6, 6.9, 2.3], [6.0, 2.2, 5.0, 1.5], [6.9, 3.2, 5.7, 2.3], [5.6, 2.8, 4.9, 2.0], [7.7, 2.8, 6.7, 2.0], [6.3, 2.7, 4.9, 1.8], [6.7, 3.3, 5.7, 2.1], [7.2, 3.2, 6.0, 1.8], [6.2, 2.8, 4.8, 1.8], [6.1, 3.0, 4.9, 1.8], [6.4, 2.8, 5.6, 2.1], [7.2, 3.0, 5.8, 1.6], [7.4, 2.8, 6.1, 1.9], [7.9, 3.8, 6.4, 2.0], [6.4, 2.8, 5.6, 2.2], [6.3, 2.8, 5.1, 1.5], [6.1, 2.6, 5.6, 1.4], [7.7, 3.0, 6.1, 2.3], [6.3, 3.4, 5.6, 2.4], [6.4, 3.1, 5.5, 1.8], [6.0, 3.0, 4.8, 1.8], [6.9, 3.1, 5.4, 2.1], [6.7, 3.1, 5.6, 2.4], [6.9, 3.1, 5.1, 2.3], [5.8, 2.7, 5.1, 1.9], [6.8, 3.2, 5.9, 2.3], [6.7, 3.3, 5.7, 2.5], [6.7, 3.0, 5.2, 2.3], [6.3, 2.5, 5.0, 1.9], [6.5, 3.0, 5.2, 2.0], [6.2, 3.4, 5.4, 2.3], [5.9, 3.0, 5.1, 1.8]], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]\n"
          ]
        }
      ],
      "source": [
        "dataset = IrisDataset()\n",
        "print(\"After X-Y split:\")\n",
        "print(dataset.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCsreCNmwJ6Y"
      },
      "source": [
        "**Splitting the dataset**\n",
        "\n",
        "The next step is splitting the dataset into three sets: training, validation and test set.\n",
        "\n",
        "The first split on the dataset creates the **validation set** of **10 samples** and leaves **140 remaining** samples for the train-test split.\n",
        "\n",
        "The training-test split is done in **80/20** proportions, which gives us **112 training samples** and **28 test samples**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ps4Pc1QpeWLl",
        "outputId": "b94e6ae4-e3f5-45da-fba8-268d80739562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 validation samples.\n",
            "140 remaining samples.\n"
          ]
        }
      ],
      "source": [
        "validation_set, remaining = torch.utils.data.random_split(dataset, [10, int((dataset.__len__())-10)])   # 10 samples for validation\n",
        "print(str(len(validation_set)) + \" validation samples.\")\n",
        "print(str(len(remaining)) + \" remaining samples.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ada6PD75sI8_",
        "outputId": "a4a338d2-474d-4dd7-b493-b262a2341cb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "112 training samples.\n",
            "28 test samples.\n"
          ]
        }
      ],
      "source": [
        "lengths = [int(len(remaining)*0.8), int(len(remaining)*0.2)]  # 80/20 split\n",
        "training_set, test_set = torch.utils.data.random_split(remaining, lengths)\n",
        "print(str(len(training_set)) + \" training samples.\")\n",
        "print(str(len(test_set)) + \" test samples.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6og3C3fRGFTu"
      },
      "source": [
        "Initializing DataLoader iterator objects for our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gJq-T9g-GNnM"
      },
      "outputs": [],
      "source": [
        "train_iterator = DataLoader(training_set)   # no batches since the dataset is very small\n",
        "validation_iterator = DataLoader(validation_set)\n",
        "test_iterator = DataLoader(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7Xcu29WExFa"
      },
      "source": [
        "## **The models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGGwxx04lYUi"
      },
      "source": [
        "The models trained in this task are **N-layer perceptrons**, but more specifically - **multilayer perceptrons**.\n",
        "\n",
        "A **single layer perceptron** (or simply **perceptron**) is the simplest type of an artificial neural network and it can only classify cases with a binary target (0, 1). Our classification task involves three target classes, so it would not work. Therefore, we are only considering **MLP**s (multilayer perceptrons).\n",
        "\n",
        "A multilayer perceptron is a fully connected class of feedforward artificial neural network (ANN). It consists of at least three layers:\n",
        "*   input layer\n",
        "*   hidden layer(s)\n",
        "*   output layer\n",
        "\n",
        "Each node (except from the input nodes) is a neuron which uses a nonlinear activation function. Training is done using a supervised learning technique called backpropagation. We are using the Pytorch library to implement it.\n",
        "\n",
        "Our goal in this task is to see how number of layers in a NN affects final metrics. To accomplish this, we created a *MultilayerPerceptron* class which allows us to create instances of models with different numbers of hidden layers.\n",
        "\n",
        "When initializing an instance of this class, apart from passing input, hidden and output dimensions, we are also passing the number of hidden layers. The model's multiple hidden layers are activated using ReLU function.\n",
        "\n",
        "We tested following MLPs:\n",
        "\n",
        "*   with 2 layers (so 1 hidden layer)\n",
        "*   with 3 layers (so 2 hidden layers)\n",
        "*   with 4 layers (so 3 hidden layers)\n",
        "*   with 5 layers (so 4 hidden layers)\n",
        "\n",
        "All of mentioned MLPs were implemented with two cost functions: Mean Squared Error (MSE) and Mean Absolute Error (MAE). Even though these loss functions are not considered the first choices for typical classification tasks, we have decided to use them, because they are simple and the output of our nets is just one value which (if the model does well) should be close to the target value (0, 1 or 2 depending on the iris species). So these loss functions simply measure how far the predicted value deviated from the target value.\n",
        "\n",
        "All MLPs are also trained in the same amount of **epochs** - **15**, in order to focus on the multiple layers' effect on the network, instead of optimizing each network by adjusting to its size (for example trying increasing the number of epochs to see if it improves).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPwf5IydAyfb"
      },
      "source": [
        "**Defining the N-layer perceptron model class with a parameter-specified number of hidden layers:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "xDgKy39twYhG"
      },
      "outputs": [],
      "source": [
        "class MultilayerPerceptron(nn.Module):\n",
        "  def __init__(self, input_dim, num_hidden_layers, hidden_dim, output_dim):\n",
        "    super(MultilayerPerceptron, self).__init__()\n",
        "\n",
        "    # input layer\n",
        "    self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
        "\n",
        "    # hidden layers\n",
        "    self.hidden_layers = nn.ModuleList()\n",
        "    for i in range(0, num_hidden_layers):\n",
        "      self.hidden_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "\n",
        "    # output layer\n",
        "    self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.input_layer(x)\n",
        "    out = F.relu(out)\n",
        "\n",
        "    for layer in self.hidden_layers:\n",
        "      out = layer(out)\n",
        "      out = F.relu(out)\n",
        "\n",
        "    out = self.output_layer(out)\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfAxW6E35Lyi"
      },
      "source": [
        "Switching to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "e3Ls8h385K5C",
        "outputId": "a5393cee-b65f-4b0f-f9ac-2dcda7b3adca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# CUDA for Pytorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "print(\"Using device: \" + str(device))\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX1iX62N5PRB"
      },
      "source": [
        "# Initializing, training and testing N-layer perceptrons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHOaQwD683Ti"
      },
      "source": [
        "## Two-layer perceptron\n",
        "\n",
        "Input layer -> hidden layer -> output layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7kiqjE740h3"
      },
      "source": [
        "**Trained with Mean Squared Error loss function:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "I21sBUnpyLur",
        "outputId": "1dd61ab6-236d-4046-8823-2c8d82766f21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultilayerPerceptron(\n",
            "  (input_layer): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=3, out_features=3, bias=True)\n",
            "  )\n",
            "  (output_layer): Linear(in_features=3, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Training the two-layer perceptron with MSE loss...\n",
            "\n",
            "Starting epoch 1...\n",
            "Training loss = 0.33100258152437945\n",
            "Validation loss = 0.0779700659273658\n",
            "Starting epoch 2...\n",
            "Training loss = 0.12218850151111837\n",
            "Validation loss = 0.08078202089527622\n",
            "Starting epoch 3...\n",
            "Training loss = 0.10153173815332549\n",
            "Validation loss = 0.08205568028752168\n",
            "Starting epoch 4...\n",
            "Training loss = 0.09446928187425588\n",
            "Validation loss = 0.08160775287142315\n",
            "Starting epoch 5...\n",
            "Training loss = 0.08924125694540626\n",
            "Validation loss = 0.07456750599376391\n",
            "Starting epoch 6...\n",
            "Training loss = 0.0846632627774235\n",
            "Validation loss = 0.07330675255507231\n",
            "Starting epoch 7...\n",
            "Training loss = 0.07972553212032706\n",
            "Validation loss = 0.07147570378147065\n",
            "Starting epoch 8...\n",
            "Training loss = 0.07590219945601108\n",
            "Validation loss = 0.0699121905840002\n",
            "Starting epoch 9...\n",
            "Training loss = 0.07297222810286032\n",
            "Validation loss = 0.06829075798741542\n",
            "Starting epoch 10...\n",
            "Training loss = 0.07058361041749325\n",
            "Validation loss = 0.06658291883973107\n",
            "Starting epoch 11...\n",
            "Training loss = 0.06848184405294352\n",
            "Validation loss = 0.06490440747802495\n",
            "Starting epoch 12...\n",
            "Training loss = 0.0666961007600443\n",
            "Validation loss = 0.06326627907546936\n",
            "Starting epoch 13...\n",
            "Training loss = 0.06516037082713362\n",
            "Validation loss = 0.061690903530688956\n",
            "Starting epoch 14...\n",
            "Training loss = 0.06382640337737608\n",
            "Validation loss = 0.06019904654385897\n",
            "Starting epoch 15...\n",
            "Training loss = 0.06265789945635206\n",
            "Validation loss = 0.05880419578170404\n"
          ]
        }
      ],
      "source": [
        "# initialize the NN to have 1 hidden layer\n",
        "two_layer_nn1 = MultilayerPerceptron(4, 1, 3, 1)\n",
        "print(two_layer_nn1)\n",
        "\n",
        "# transfer model to GPU\n",
        "two_layer_nn1.to(device)\n",
        "\n",
        "# define loss function and optimizer (stochastic gradient descent)\n",
        "loss_function = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(two_layer_nn1.parameters(), lr=0.01)\n",
        "\n",
        "print(\"\\nTraining the two-layer perceptron with MSE loss...\\n\")\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "# loop over epochs\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Starting epoch \" + str(epoch + 1) + \"...\")\n",
        "  train_loss = 0.0\n",
        "\n",
        "  # training\n",
        "  for features, label in train_iterator:\n",
        "    # transfer to GPU\n",
        "    features = torch.concat(features).to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # model computations\n",
        "\n",
        "    # set gradients to 0 before calculating loss\n",
        "    two_layer_nn1.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    output = two_layer_nn1(features.float())\n",
        "\n",
        "    # calculate the loss function\n",
        "    loss = loss_function(output, label.float())\n",
        "\n",
        "    # backpropagation, calculating gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  print(\"Training loss = \" + str(train_loss/len(train_iterator)))\n",
        "  train_losses.append(train_loss/len(train_iterator))\n",
        "\n",
        "  # validation\n",
        "  with torch.set_grad_enabled(False):\n",
        "    valid_loss = 0.0\n",
        "    for features, label in validation_iterator:\n",
        "      # transfer to GPU\n",
        "      features = torch.concat(features).to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      # model computations\n",
        "      output = two_layer_nn1(features.float())\n",
        "      loss = loss_function(output, label.float())\n",
        "\n",
        "      valid_loss += loss.item()\n",
        "\n",
        "    print(\"Validation loss = \" + str(valid_loss/len(validation_iterator)))\n",
        "    valid_losses.append(valid_loss/len(validation_iterator))\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NwGq8Q11tYf"
      },
      "source": [
        "**Plot the training-validation curve**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "BKBOuh2n1wOj",
        "outputId": "da6e67ad-74ce-4809-a0d8-2422af749b6a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = list(range(1, num_epochs+1))\n",
        "plt.plot(epochs, train_losses, 'ro', label=\"Training loss\")\n",
        "plt.plot(epochs, valid_losses, 'g*', label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afVharWbE5XX"
      },
      "source": [
        "**Testing the model's accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "137huHkfE8xY",
        "outputId": "578fce56-484a-4a8d-a6cc-a090c569f3d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model based on 28 test samples: 96.42857142857143\n"
          ]
        }
      ],
      "source": [
        "with torch.set_grad_enabled(False):\n",
        "    accuracy = 0.0\n",
        "    for features, label in test_iterator:\n",
        "      # transfer to GPU\n",
        "      features = torch.concat(features).to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      output = two_layer_nn1(features.float())\n",
        "\n",
        "      predicted = torch.round(output)\n",
        "      accuracy += (predicted == label).sum().item()\n",
        "\n",
        "    print(\"Accuracy of the model based on \" + str(len(test_iterator)) + \" test samples: \" + str(100 * accuracy/len(test_iterator)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL6FW0lQCEEr"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "The **two-layer perceptron** model performed **very well**. Based on the training-validation curve, it seems that after 15 epochs it **converges** beautifully, so it was performing very satisfactorily on both training and validation data. It also scored very high accuracy: **96%**.\n",
        "\n",
        "Our dataset was very small, there are only 112 samples for training, so to accomplish good results, **a good model is one which is able to generalize well**. This one certainly did.\n",
        "\n",
        "It also seems that the **Mean Squared Error** metric contributed to quite **stable** results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHK8i_rZ1gun"
      },
      "source": [
        "**Trained with Mean Absolute Error loss function:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rLd3QUnw1hLv",
        "outputId": "03f2164b-6739-4132-b16b-ff4c97ac6916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultilayerPerceptron(\n",
            "  (input_layer): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=3, out_features=3, bias=True)\n",
            "  )\n",
            "  (output_layer): Linear(in_features=3, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Training the two-layer perceptron with MAE loss...\n",
            "\n",
            "Starting epoch 1...\n",
            "Training loss = 0.5814344228378364\n",
            "Validation loss = 0.2700388580560684\n",
            "Starting epoch 2...\n",
            "Training loss = 0.2793390882600631\n",
            "Validation loss = 0.2083013892173767\n",
            "Starting epoch 3...\n",
            "Training loss = 0.23710989393293858\n",
            "Validation loss = 0.18174836933612823\n",
            "Starting epoch 4...\n",
            "Training loss = 0.24427837479327405\n",
            "Validation loss = 0.2233034610748291\n",
            "Starting epoch 5...\n",
            "Training loss = 0.23904717074973242\n",
            "Validation loss = 0.13327444791793824\n",
            "Starting epoch 6...\n",
            "Training loss = 0.2349440579169563\n",
            "Validation loss = 0.24994919300079346\n",
            "Starting epoch 7...\n",
            "Training loss = 0.22236932627856731\n",
            "Validation loss = 0.3288120567798615\n",
            "Starting epoch 8...\n",
            "Training loss = 0.21953046587961061\n",
            "Validation loss = 0.2803720772266388\n",
            "Starting epoch 9...\n",
            "Training loss = 0.22081837137894972\n",
            "Validation loss = 0.14470461010932922\n",
            "Starting epoch 10...\n",
            "Training loss = 0.23274494747498206\n",
            "Validation loss = 0.23026169538497926\n",
            "Starting epoch 11...\n",
            "Training loss = 0.22010987385043077\n",
            "Validation loss = 0.22948270440101623\n",
            "Starting epoch 12...\n",
            "Training loss = 0.2185690234016095\n",
            "Validation loss = 0.2857395589351654\n",
            "Starting epoch 13...\n",
            "Training loss = 0.22348306673978055\n",
            "Validation loss = 0.1400468409061432\n",
            "Starting epoch 14...\n",
            "Training loss = 0.22268565957035338\n",
            "Validation loss = 0.15414865016937257\n",
            "Starting epoch 15...\n",
            "Training loss = 0.22308766389531748\n",
            "Validation loss = 0.153840172290802\n"
          ]
        }
      ],
      "source": [
        "# initialize the NN to have 1 hidden layer\n",
        "two_layer_nn2 = MultilayerPerceptron(4, 1, 3, 1)\n",
        "print(two_layer_nn2)\n",
        "\n",
        "# transfer model to GPU\n",
        "two_layer_nn2.to(device)\n",
        "\n",
        "# define loss function and optimizer (stochastic gradient descent)\n",
        "loss_function = torch.nn.L1Loss()\n",
        "optimizer = torch.optim.SGD(two_layer_nn2.parameters(), lr=0.01)\n",
        "\n",
        "print(\"\\nTraining the two-layer perceptron with MAE loss...\\n\")\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "# loop over epochs\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Starting epoch \" + str(epoch + 1) + \"...\")\n",
        "  train_loss = 0.0\n",
        "\n",
        "  # training\n",
        "  for features, label in train_iterator:\n",
        "    # transfer to GPU\n",
        "    features = torch.concat(features).to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # model computations\n",
        "\n",
        "    # set gradients to 0 before calculating loss\n",
        "    two_layer_nn2.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    output = two_layer_nn2(features.float())\n",
        "\n",
        "    # calculate the loss function\n",
        "    loss = loss_function(output, label.float())\n",
        "\n",
        "    # backpropagation, calculating gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  print(\"Training loss = \" + str(train_loss/len(train_iterator)))\n",
        "  train_losses.append(train_loss/len(train_iterator))\n",
        "\n",
        "  # validation\n",
        "  with torch.set_grad_enabled(False):\n",
        "    valid_loss = 0.0\n",
        "    for features, label in validation_iterator:\n",
        "      # transfer to GPU\n",
        "      features = torch.concat(features).to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      # model computations\n",
        "      output = two_layer_nn2(features.float())\n",
        "      loss = loss_function(output, label.float())\n",
        "\n",
        "      valid_loss += loss.item()\n",
        "\n",
        "    print(\"Validation loss = \" + str(valid_loss/len(validation_iterator)))\n",
        "    valid_losses.append(valid_loss/len(validation_iterator))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT_SDJKC4ec-"
      },
      "source": [
        "**Plot the training-validation curve**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "Wg8KWUlK4fOa",
        "outputId": "f230c9b7-56cc-43b7-d0fd-06f90ba3f82c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = list(range(1, num_epochs+1))\n",
        "plt.plot(epochs, train_losses, 'ro', label=\"Training loss\")\n",
        "plt.plot(epochs, valid_losses, 'g*', label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx6DRjz2MCz8"
      },
      "source": [
        "**Testing the model's accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aAJA3KeeMDxf",
        "outputId": "df996e1c-0bc0-4f81-d1c8-7c0b6e200f15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model based on 28 test samples: 92.85714285714286\n"
          ]
        }
      ],
      "source": [
        "with torch.set_grad_enabled(False):\n",
        "    accuracy = 0.0\n",
        "    for features, label in test_iterator:\n",
        "      # transfer to GPU\n",
        "      features = torch.concat(features).to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      output = two_layer_nn2(features.float())\n",
        "\n",
        "      predicted = torch.round(output)\n",
        "      accuracy += (predicted == label).sum().item()\n",
        "\n",
        "    print(\"Accuracy of the model based on \" + str(len(test_iterator)) + \" test samples: \" + str(100 * accuracy/len(test_iterator)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s96wYzVjeLmi"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "The second two-layer perceptron is trained using a different loss function - **Mean Absolute Error**, and it is visible right from first looking at the training-validation curve, as well as the accuracy, that this option yields more **unstable** results. The training loss decreases, but becomes stagnant after dropping to about 0.2. The validation loss does not follow any sensible pattern, so the model is not handling unobserved samples well.\n",
        "\n",
        "The accuracy is a bit lower than in case of MSE, but still not bad - **92.9%**.\n",
        "\n",
        "The reason why **MSE** proved to yield better results than **MAE** may be that because MSE uses a squared value - **any large deviations from the target value are heavily penalized**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WklWKtRq5AG9"
      },
      "source": [
        "## Three-layer perceptron\n",
        "\n",
        "Input layer -> hidden layer -> hidden layer -> output layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_rljMBk9TFc"
      },
      "source": [
        "**Trained with Mean Squared Error loss function:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xdMhM6z7Exej",
        "outputId": "d83dc1d6-a1d1-489a-9302-6d406a6f969c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultilayerPerceptron(\n",
            "  (input_layer): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (1): Linear(in_features=3, out_features=3, bias=True)\n",
            "  )\n",
            "  (output_layer): Linear(in_features=3, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Training the three-layer perceptron with MSE loss...\n",
            "\n",
            "Starting epoch 1...\n",
            "Training loss = 0.6383804970771182\n",
            "Validation loss = 0.28213832250912674\n",
            "Starting epoch 2...\n",
            "Training loss = 0.2506431064620642\n",
            "Validation loss = 0.08813927117735147\n",
            "Starting epoch 3...\n",
            "Training loss = 0.1314592558570991\n",
            "Validation loss = 0.11015951464651152\n",
            "Starting epoch 4...\n",
            "Training loss = 0.11723326247772548\n",
            "Validation loss = 0.11963264919904759\n",
            "Starting epoch 5...\n",
            "Training loss = 0.10676166445179344\n",
            "Validation loss = 0.1308299603580963\n",
            "Starting epoch 6...\n",
            "Training loss = 0.09609459767934934\n",
            "Validation loss = 0.14456666345940902\n",
            "Starting epoch 7...\n",
            "Training loss = 0.0907893219319545\n",
            "Validation loss = 0.1525502649252303\n",
            "Starting epoch 8...\n",
            "Training loss = 0.08364710027807885\n",
            "Validation loss = 0.1405965701676905\n",
            "Starting epoch 9...\n",
            "Training loss = 0.07588096264693535\n",
            "Validation loss = 0.1497926690732129\n",
            "Starting epoch 10...\n",
            "Training loss = 0.07571751994356443\n",
            "Validation loss = 0.1496393772540614\n",
            "Starting epoch 11...\n",
            "Training loss = 0.07252394248420597\n",
            "Validation loss = 0.1474352712277323\n",
            "Starting epoch 12...\n",
            "Training loss = 0.06949921245532462\n",
            "Validation loss = 0.14491173797287046\n",
            "Starting epoch 13...\n",
            "Training loss = 0.0672660484749252\n",
            "Validation loss = 0.14663543072529137\n",
            "Starting epoch 14...\n",
            "Training loss = 0.06556907545660096\n",
            "Validation loss = 0.14142556895967573\n",
            "Starting epoch 15...\n",
            "Training loss = 0.06362951142579083\n",
            "Validation loss = 0.13796997864264995\n"
          ]
        }
      ],
      "source": [
        "# initialize the NN to have 2 hidden layers\n",
        "three_layer_nn1 = MultilayerPerceptron(4, 2, 3, 1)\n",
        "print(three_layer_nn1)\n",
        "\n",
        "# transfer model to GPU\n",
        "three_layer_nn1.to(device)\n",
        "\n",
        "# define loss function and optimizer (stochastic gradient descent)\n",
        "loss_function = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(three_layer_nn1.parameters(), lr=0.01)\\\n",
        "\n",
        "print(\"\\nTraining the three-layer perceptron with MSE loss...\\n\")\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "# loop over epochs\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Starting epoch \" + str(epoch + 1) + \"...\")\n",
        "  train_loss = 0.0\n",
        "\n",
        "  # training\n",
        "  for features, label in train_iterator:\n",
        "    # transfer to GPU\n",
        "    features = torch.concat(features).to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # model computations\n",
        "\n",
        "    # set gradients to 0 before calculating loss\n",
        "    three_layer_nn1.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    output = three_layer_nn1(features.float())\n",
        "\n",
        "    # calculate the loss function\n",
        "    loss = loss_function(output, label.float())\n",
        "\n",
        "    # backpropagate\n",
        "    loss.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  print(\"Training loss = \" + str(train_loss/len(train_iterator)))\n",
        "  train_losses.append(train_loss/len(train_iterator))\n",
        "\n",
        "  # validation\n",
        "  with torch.set_grad_enabled(False):\n",
        "    valid_loss = 0.0\n",
        "    for features, label in validation_iterator:\n",
        "      # transfer to GPU\n",
        "      features = torch.concat(features).to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      # model computations\n",
        "      output = three_layer_nn1(features.float())\n",
        "      loss = loss_function(output, label.float())\n",
        "\n",
        "      valid_loss += loss.item()\n",
        "\n",
        "    print(\"Validation loss = \" + str(valid_loss/len(validation_iterator)))\n",
        "    valid_losses.append(valid_loss/len(validation_iterator))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzcV8kKY8Li5"
      },
      "source": [
        "**Plot the training-validation curve**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "yQlvtFzK8MXQ",
        "outputId": "2362ab23-142f-46a5-f802-9fafe9a11de5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = list(range(1, num_epochs+1))\n",
        "plt.plot(epochs, train_losses, 'ro', label=\"Training loss\")\n",
        "plt.plot(epochs, valid_losses, 'g*', label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dukved9KMGoB"
      },
      "source": [
        "**Testing the model's accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TFJVbpSvMHd3",
        "outputId": "a6ce3c83-a0f3-4ce3-d378-f94f17fd9306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model based on 28 test samples: 92.85714285714286\n"
          ]
        }
      ],
      "source": [
        "with torch.set_grad_enabled(False):\n",
        "    accuracy = 0.0\n",
        "    for features, label in test_iterator:\n",
        "      # transfer to GPU\n",
        "      features = torch.concat(features).to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      output = three_layer_nn1(features.float())\n",
        "      loss = loss_function(output, label.float())\n",
        "\n",
        "      predicted = torch.round(output)\n",
        "      accuracy += (predicted == label).sum().item()\n",
        "\n",
        "    print(\"Accuracy of the model based on \" + str(len(test_iterator)) + \" test samples: \" + str(100 * accuracy/len(test_iterator)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkvzsLV3jrJi"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "The **three-layer perceptron** seemed to learn how to generalize data well very fast. It **converged after just 4 epoch**s, so at that point it would have potential to be an acceptable model. However, **after those 4 epochs** the model started **overfitting**, so the **number of layers became too much for current problem's complexity**. It lost its generalization ability. However, the accuracy is still not bad - **92.9%**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8sLp6z0AloS"
      },
      "source": [
        "**Trained with Mean Absolute Error loss function:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sq3RYQKNAmBr",
        "outputId": "97d4acc5-8855-4533-a65f-36548ee129e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultilayerPerceptron(\n",
            "  (input_layer): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (1): Linear(in_features=3, out_features=3, bias=True)\n",
            "  )\n",
            "  (output_layer): Linear(in_features=3, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Training the three-layer perceptron with MAE loss...\n",
            "\n",
            "Starting epoch 1...\n",
            "Training loss = 0.7172680202472422\n",
            "Validation loss = 0.29666553139686586\n",
            "Starting epoch 2...\n",
            "Training loss = 0.39103851966293796\n",
            "Validation loss = 0.20042220503091812\n",
            "Starting epoch 3...\n",
            "Training loss = 0.2756162337692721\n",
            "Validation loss = 0.17516628950834273\n",
            "Starting epoch 4...\n",
            "Training loss = 0.2572048598168684\n",
            "Validation loss = 0.12779828161001205\n",
            "Starting epoch 5...\n",
            "Training loss = 0.24768082298604505\n",
            "Validation loss = 0.16436545103788375\n",
            "Starting epoch 6...\n",
            "Training loss = 0.24503963869730278\n",
            "Validation loss = 0.12701896578073502\n",
            "Starting epoch 7...\n",
            "Training loss = 0.23356454875985427\n",
            "Validation loss = 0.13075974881649016\n",
            "Starting epoch 8...\n",
            "Training loss = 0.22073577444202133\n",
            "Validation loss = 0.20236607939004897\n",
            "Starting epoch 9...\n",
            "Training loss = 0.23194649501238018\n",
            "Validation loss = 0.1268186718225479\n",
            "Starting epoch 10...\n",
            "Training loss = 0.23058730293996632\n",
            "Validation loss = 0.12597719728946685\n",
            "Starting epoch 11...\n",
            "Training loss = 0.22662265259506448\n",
            "Validation loss = 0.14406844303011895\n",
            "Starting epoch 12...\n",
            "Training loss = 0.2356920388493953\n",
            "Validation loss = 0.12507835254073144\n",
            "Starting epoch 13...\n",
            "Training loss = 0.22235700220335275\n",
            "Validation loss = 0.12998252660036086\n",
            "Starting epoch 14...\n",
            "Training loss = 0.2234579999848003\n",
            "Validation loss = 0.141012242436409\n",
            "Starting epoch 15...\n",
            "Training loss = 0.22094581379289074\n",
            "Validation loss = 0.12421125955879689\n"
          ]
        }
      ],
      "source": [
        "# initialize the NN to have 2 hidden layers\n",
        "three_layer_nn2 = MultilayerPerceptron(4, 2, 3, 1)\n",
        "print(three_layer_nn2)\n",
        "\n",
        "# transfer model to GPU\n",
        "three_layer_nn2.to(device)\n",
        "\n",
        "# define loss function and optimizer (stochastic gradient descent)\n",
        "loss_function = torch.nn.L1Loss()\n",
        "optimizer = torch.optim.SGD(three_layer_nn2.parameters(), lr=0.01)\\\n",
        "\n",
        "print(\"\\nTraining the three-layer perceptron with MAE loss...\\n\")\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "# loop over epochs\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Starting epoch \" + str(epoch + 1) + \"...\")\n",
        "  train_loss = 0.0\n",
        "\n",
        "  # training\n",
        "  for features, label in train_iterator:\n",
        "    # transfer to GPU\n",
        "    features = torch.concat(features).to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # model computations\n",
        "\n",
        "    # set gradients to 0 before calculating loss\n",
        "    three_layer_nn2.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    output = three_layer_nn2(features.float())\n",
        "\n",
        "    # calculate the loss function\n",
        "    loss = loss_function(output, label.float())\n",
        "\n",
        "    # backpropagate\n",
        "    loss.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  print(\"Training loss = \" + str(train_loss/len(train_iterator)))\n",
        "  train_losses.append(train_loss/len(train_iterator))\n",
        "\n",
        "  # validation\n",
        "  with torch.set_grad_enabled(False):\n",
        "    valid_loss = 0.0\n",
        "    for features, label in validation_iterator:\n",
        "      # transfer to GPU\n",
        "      features = torch.concat(features).to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      # model computations\n",
        "      output = three_layer_nn2(features.float())\n",
        "      loss = loss_function(output, label.float())\n",
        "\n",
        "      valid_loss += loss.item()\n",
        "\n",
        "    print(\"Validation loss = \" + str(valid_loss/len(validation_iterator)))\n",
        "    valid_losses.append(valid_loss/len(validation_iterator))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w1HwHBy8PAC"
      },
      "source": [
        "**Plot the training-validation curve**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "_JucLNob8Pu-",
        "outputId": "d8a25a26-02cb-4065-86af-deba2a33189e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = list(range(1, num_epochs+1))\n",
        "plt.plot(epochs, train_losses, 'ro', label=\"Training loss\")\n",
        "plt.plot(epochs, valid_losses, 'g*', label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY0AVvODMJTs"
      },
      "source": [
        "**Testing the model's accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OKsG1h6WMKE1",
        "outputId": "c4b7f610-6812-4a1c-fe92-5ce0f7789b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model based on 28 test samples: 89.28571428571429\n"
          ]
        }
      ],
      "source": [
        "with torch.set_grad_enabled(False):\n",
        "    accuracy = 0.0\n",
        "    for features, label in test_iterator:\n",
        "      # transfer to GPU\n",
        "      features = torch.concat(features).to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      output = three_layer_nn2(features.float())\n",
        "      loss = loss_function(output, label.float())\n",
        "\n",
        "      predicted = torch.round(output)\n",
        "      accuracy += (predicted == label).sum().item()\n",
        "\n",
        "    print(\"Accuracy of the model based on \" + str(len(test_iterator)) + \" test samples: \" + str(100 * accuracy/len(test_iterator)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU65wE-bmb8R"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "The second **three-layer perceptron**, trained with MAE loss function, again yielded worse results than the one trained with MSE.\n",
        "\n",
        "As shown on the training-validation curve, the model **failed to converge** during 15 epochs and scored an **89%** accuracy.\n",
        "\n",
        "So again, as the first three-layer perceptron, it may be that the complexity of the network is too large for current problem's complexity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxyotce081TN"
      },
      "source": [
        "## Four level perceptron\n",
        "\n",
        "Input layer -> hidden layer -> hidden layer -> hidden layer -> output layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9ZcWGF-BabM"
      },
      "source": [
        "**Trained with Mean Squared Error loss function:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xXdtgl0-RTIg",
        "outputId": "fe5dc170-7c70-4b7f-d495-6f57b724ced4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultilayerPerceptron(\n",
            "  (input_layer): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (1): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (2): Linear(in_features=3, out_features=3, bias=True)\n",
            "  )\n",
            "  (output_layer): Linear(in_features=3, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Training the four-layer perceptron with MSE loss...\n",
            "\n",
            "Starting epoch 1...\n",
            "Training loss = 1.1635109783580577\n",
            "Validation loss = 0.45350931528955696\n",
            "Starting epoch 2...\n",
            "Training loss = 0.6977145188315603\n",
            "Validation loss = 0.4587149902712554\n",
            "Starting epoch 3...\n",
            "Training loss = 0.6967986928148743\n",
            "Validation loss = 0.45987345310859384\n",
            "Starting epoch 4...\n",
            "Training loss = 0.6962317282504306\n",
            "Validation loss = 0.46100258617661893\n",
            "Starting epoch 5...\n",
            "Training loss = 0.695686765706796\n",
            "Validation loss = 0.4621101112104952\n",
            "Starting epoch 6...\n",
            "Training loss = 0.6951612423304466\n",
            "Validation loss = 0.46319714314304294\n",
            "Starting epoch 7...\n",
            "Training loss = 0.6946532786200805\n",
            "Validation loss = 0.46426479071378707\n",
            "Starting epoch 8...\n",
            "Training loss = 0.6941633134657812\n",
            "Validation loss = 0.4653116765897721\n",
            "Starting epoch 9...\n",
            "Training loss = 0.6936899787680285\n",
            "Validation loss = 0.46633884790353475\n",
            "Starting epoch 10...\n",
            "Training loss = 0.6932317967432076\n",
            "Validation loss = 0.46734719777014105\n",
            "Starting epoch 11...\n",
            "Training loss = 0.6927890095949435\n",
            "Validation loss = 0.46833563500549646\n",
            "Starting epoch 12...\n",
            "Training loss = 0.6923606375769806\n",
            "Validation loss = 0.46930499982554463\n",
            "Starting epoch 13...\n",
            "Training loss = 0.6919459470812593\n",
            "Validation loss = 0.4702554602641612\n",
            "Starting epoch 14...\n",
            "Training loss = 0.6915443044488094\n",
            "Validation loss = 0.47118741313461215\n",
            "Starting epoch 15...\n",
            "Training loss = 0.691155150210672\n",
            "Validation loss = 0.4721009069820866\n"
          ]
        }
      ],
      "source": [
        "# initialize the NN to have 3 hidden layers\n",
        "four_layer_nn1 = MultilayerPerceptron(4, 3, 3, 1)\n",
        "print(four_layer_nn1)\n",
        "\n",
        "# transfer model to GPU\n",
        "four_layer_nn1.to(device)\n",
        "\n",
        "# define loss function and optimizer (stochastic gradient descent)\n",
        "loss_function = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(four_layer_nn1.parameters(), lr=0.01)\n",
        "\n",
        "print(\"\\nTraining the four-layer perceptron with MSE loss...\\n\")\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "# loop over epochs\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Starting epoch \" + str(epoch + 1) + \"...\")\n",
        "  train_loss = 0.0\n",
        "\n",
        "  # training\n",
        "  for features, label in train_iterator:\n",
        "    # transfer to GPU\n",
        "    features = torch.concat(features).to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # model computations\n",
        "\n",
        "    # set gradients to 0 before calculating loss\n",
        "    four_layer_nn1.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    output = four_layer_nn1(features.float())\n",
        "\n",
        "    loss = loss_function(output, label.float())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  print(\"Training loss = \" + str(train_loss/len(train_iterator)))\n",
        "  train_losses.append(train_loss/len(train_iterator))\n",
        "\n",
        "  # validation\n",
        "  with torch.set_grad_enabled(False):\n",
        "    valid_loss = 0.0\n",
        "    for features, label in validation_iterator:\n",
        "      # transfer to GPU\n",
        "      features = torch.concat(features).to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      # model computations\n",
        "      output = four_layer_nn1(features.float())\n",
        "      loss = loss_function(output, label.float())\n",
        "\n",
        "      valid_loss += loss.item()\n",
        "\n",
        "    print(\"Validation loss = \" + str(valid_loss/len(validation_iterator)))\n",
        "    valid_losses.append(valid_loss/len(validation_iterator))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4u4TtA08Szu"
      },
      "source": [
        "**Plot the training-validation curve**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "bObDBAlk8Tu7",
        "outputId": "ef7491c6-76c5-452b-d934-d06adb4de096"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = list(range(1, num_epochs+1))\n",
        "plt.plot(epochs, train_losses, 'ro', label=\"Training loss\")\n",
        "plt.plot(epochs, valid_losses, 'g*', label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD4jR3N0MTek"
      },
      "source": [
        "**Testing the model's accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DlaW3FWxMUP9",
        "outputId": "9b877896-487a-4b13-c271-be3eb588babc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model based on 28 test samples: 28.571428571428573\n"
          ]
        }
      ],
      "source": [
        "with torch.set_grad_enabled(False):\n",
        "    accuracy = 0.0\n",
        "    for features, label in test_iterator:\n",
        "      # transfer to GPU\n",
        "      features = torch.concat(features).to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      output = four_layer_nn1(features.float())\n",
        "\n",
        "      predicted = torch.round(output)\n",
        "      \n",
        "      accuracy += (predicted == label).sum().item()\n",
        "\n",
        "    print(\"Accuracy of the model based on \" + str(len(test_iterator)) + \" test samples: \" + str(100 * accuracy/len(test_iterator)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXd6GcfmodjZ"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "When we start observing perceptrons with **3 hidden layers or more**, the **negative effect** of increased number of hidden layers on the **current problem** becomes quite transparent.\n",
        "\n",
        "The model did not manage to learn how to generalize at all and for all samples it predicts the same value which is right only in **28%** of the time, as scored accuracy shows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hI3t1JSBFTl"
      },
      "source": [
        "**Trained with Mean Absolute Error loss function:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UJ_3wJh4BIw8",
        "outputId": "35dd17a7-7576-48d1-b3ec-c8477935152b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultilayerPerceptron(\n",
            "  (input_layer): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (1): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (2): Linear(in_features=3, out_features=3, bias=True)\n",
            "  )\n",
            "  (output_layer): Linear(in_features=3, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Training the four-layer perceptron with MAE loss...\n",
            "\n",
            "Starting epoch 1...\n",
            "Training loss = 0.9620866047750626\n",
            "Validation loss = 0.5660091161727905\n",
            "Starting epoch 2...\n",
            "Training loss = 0.7041806748935154\n",
            "Validation loss = 0.5050746977329255\n",
            "Starting epoch 3...\n",
            "Training loss = 0.6820456135485854\n",
            "Validation loss = 0.5071509420871735\n",
            "Starting epoch 4...\n",
            "Training loss = 0.6818227512495858\n",
            "Validation loss = 0.5091474413871765\n",
            "Starting epoch 5...\n",
            "Training loss = 0.6822800455348832\n",
            "Validation loss = 0.5014684975147248\n",
            "Starting epoch 6...\n",
            "Training loss = 0.6817054258925574\n",
            "Validation loss = 0.5034299314022064\n",
            "Starting epoch 7...\n",
            "Training loss = 0.681507118578468\n",
            "Validation loss = 0.505307799577713\n",
            "Starting epoch 8...\n",
            "Training loss = 0.681325191365821\n",
            "Validation loss = 0.5070998787879943\n",
            "Starting epoch 9...\n",
            "Training loss = 0.6811044226799693\n",
            "Validation loss = 0.5087996363639832\n",
            "Starting epoch 10...\n",
            "Training loss = 0.6815597436257771\n",
            "Validation loss = 0.5010719418525695\n",
            "Starting epoch 11...\n",
            "Training loss = 0.6809159607759544\n",
            "Validation loss = 0.502674686908722\n",
            "Starting epoch 12...\n",
            "Training loss = 0.6806528616164412\n",
            "Validation loss = 0.5041512370109558\n",
            "Starting epoch 13...\n",
            "Training loss = 0.6804145803408963\n",
            "Validation loss = 0.5054995238780975\n",
            "Starting epoch 14...\n",
            "Training loss = 0.6801011466554233\n",
            "Validation loss = 0.5066988706588745\n",
            "Starting epoch 15...\n",
            "Training loss = 0.6801809748368604\n",
            "Validation loss = 0.4986058950424194\n"
          ]
        }
      ],
      "source": [
        "# initialize the NN to have 3 hidden layers\n",
        "four_layer_nn2 = MultilayerPerceptron(4, 3, 3, 1)\n",
        "print(four_layer_nn2)\n",
        "\n",
        "# transfer model to GPU\n",
        "four_layer_nn2.to(device)\n",
        "\n",
        "# define loss function and optimizer (stochastic gradient descent)\n",
        "loss_function = torch.nn.L1Loss()\n",
        "optimizer = torch.optim.SGD(four_layer_nn2.parameters(), lr=0.01)\n",
        "\n",
        "print(\"\\nTraining the four-layer perceptron with MAE loss...\\n\")\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "# loop over epochs\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Starting epoch \" + str(epoch + 1) + \"...\")\n",
        "  train_loss = 0.0\n",
        "\n",
        "  # training\n",
        "  for features, label in train_iterator:\n",
        "    # transfer to GPU\n",
        "    features = torch.concat(features).to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # model computations\n",
        "\n",
        "    # set gradients to 0 before calculating loss\n",
        "    four_layer_nn2.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    output = four_layer_nn2(features.float())\n",
        "\n",
        "    loss = loss_function(output, label.float())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  print(\"Training loss = \" + str(train_loss/len(train_iterator)))\n",
        "  train_losses.append(train_loss/len(train_iterator))\n",
        "\n",
        "  # validation\n",
        "  with torch.set_grad_enabled(False):\n",
        "    valid_loss = 0.0\n",
        "    for features, label in validation_iterator:\n",
        "      # transfer to GPU\n",
        "      features = torch.concat(features).to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      # model computations\n",
        "      output = four_layer_nn2(features.float())\n",
        "      loss = loss_function(output, label.float())\n",
        "\n",
        "      valid_loss += loss.item()\n",
        "\n",
        "    print(\"Validation loss = \" + str(valid_loss/len(validation_iterator)))\n",
        "    valid_losses.append(valid_loss/len(validation_iterator))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bJ7lhqa8VzD"
      },
      "source": [
        "**Plot the training-validation curve**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "10dPTPl18Wjk",
        "outputId": "f8c99ee6-aec2-4356-897c-70350a4e585c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAacElEQVR4nO3df3RU9Z3/8ecbgiQxoFtAoQQIehBUfiQkgCUV0bYrigcEtYLZag5WDKvFL/1hsXwrFE+6e1bOrl+PyHdTW+mP1OBRl8WtXVsRBGr9loAB5FdFfhlFinSFWEgl+P7+MZM0hPyYkJnM3Ovrcc6czL33M5/7Tu7Ma24+984dc3dERCT4uiS7ABERiQ8FuohISCjQRURCQoEuIhISCnQRkZBIS9aKe/fu7Tk5OclavYhIIG3atOlDd+/T3LKkBXpOTg6VlZXJWr2ISCCZ2YGWlmnIRUQkJBToIiIhoUAXEQmJpI2hi0jnO3XqFNXV1dTW1ia7FGlDeno62dnZdOvWLebHKNBFPkOqq6vp0aMHOTk5mFmyy5EWuDtHjx6lurqawYMHx/y4YA25lJdDTg506RL5WV6e7IpEAqW2tpZevXopzFOcmdGrV692/ycVnD308nKYPRtOnIhMHzgQmQYoKkpeXSIBozAPhnPZTsHZQ1+w4G9hXu/Eich8EREJUKAfPNi++SKSco4ePUpubi65ubn07duX/v37N0x/8sknrT62srKSuXPntrmO8ePHx6XWtWvXctNNN8Wlr84SnEAfOLB980Wk4+J83KpXr15UVVVRVVVFSUkJ8+bNa5g+77zzqKura/GxBQUFPP74422u4/XXX+9QjUEWnEAvLYXMzDPnZWZG5otI/NUftzpwANz/dtwqzicjFBcXU1JSwrhx43jwwQf5wx/+wBe+8AXy8vIYP348u3fvBs7cY160aBGzZs1i4sSJXHLJJWcEfVZWVkP7iRMncuuttzJs2DCKioqo/4a2l156iWHDhpGfn8/cuXPb3BP/85//zM0338zIkSO56qqr2Lp1KwCvvfZaw38YeXl51NTUcOjQISZMmEBubi7Dhw9n/fr1cf17tSY4B0XrD3wuWBAZZhk4MBLmOiAqkhitHbeK8+uuurqa119/na5du3L8+HHWr19PWloar7zyCt/73vd4/vnnz3rMrl27WLNmDTU1NQwdOpQ5c+acdc72m2++yfbt2/n85z9PYWEhv/vd7ygoKODee+9l3bp1DB48mJkzZ7ZZ38KFC8nLy2PlypW8+uqr3HnnnVRVVbFkyRKWLl1KYWEhH3/8Menp6ZSVlXH99dezYMECTp8+zYmmf8MECk6gQ+RJpAAX6RydeNzqtttuo2vXrgAcO3aMu+66i7fffhsz49SpU80+ZvLkyXTv3p3u3btz0UUXcfjwYbKzs89oM3bs2IZ5ubm57N+/n6ysLC655JKG87tnzpxJWVlZq/Vt2LCh4U3luuuu4+jRoxw/fpzCwkK++c1vUlRUxPTp08nOzmbMmDHMmjWLU6dOcfPNN5Obm9uhv017BGfIRUQ6Vycetzr//PMb7n//+9/n2muv5a233uLFF19s8Vzs7t27N9zv2rVrs+PvsbTpiPnz5/PUU09x8uRJCgsL2bVrFxMmTGDdunX079+f4uJifvazn8V1na1RoItI85J03OrYsWP0798fgOXLl8e9/6FDh7J37172798PwIoVK9p8zNVXX0159NjB2rVr6d27Nz179uSdd95hxIgRfPe732XMmDHs2rWLAwcOcPHFF3PPPffw9a9/nc2bN8f9d2iJAl1EmldUBGVlMGgQmEV+lpUlfNjzwQcf5KGHHiIvLy/ue9QAGRkZPPnkk0yaNIn8/Hx69OjBBRdc0OpjFi1axKZNmxg5ciTz58/npz/9KQCPPfYYw4cPZ+TIkXTr1o0bbriBtWvXMmrUKPLy8lixYgUPPPBA3H+Hllj9Ud/OVlBQ4PqCC5HOtXPnTi6//PJkl5F0H3/8MVlZWbg79913H0OGDGHevHnJLusszW0vM9vk7gXNtdceuoh85vzoRz8iNzeXK6+8kmPHjnHvvfcmu6S4CNZZLiIicTBv3ryU3CPvKO2hi4iEhAJdRCQkFOgiIiGhQBcRCQkFuoh0mmuvvZaXX375jHmPPfYYc+bMafExEydOpP4U5xtvvJGPPvrorDaLFi1iyZIlra575cqV7Nixo2H64Ycf5pVXXmlP+c1KpcvsKtBFpFWHag5xzfJr+ODjDzrc18yZM6moqDhjXkVFRUwXyILIVRIvvPDCc1p300BfvHgxX/7yl8+pr1SlQBeRVj2y7hE2HNzA4tcWd7ivW2+9lV/96lcNX2axf/9+3n//fa6++mrmzJlDQUEBV155JQsXLmz28Tk5OXz44YcAlJaWctlll/HFL36x4RK7EDnHfMyYMYwaNYpbbrmFEydO8Prrr7Nq1Sq+853vkJubyzvvvENxcTHPPfccAKtXryYvL48RI0Ywa9Ys/vrXvzasb+HChYwePZoRI0awa9euVn+/ZF9mV4EuIs3KKM3AfmAsq1zGp/4pyyqXYT8wMkozzrnPz33uc4wdO5Zf//rXQGTv/Ktf/SpmRmlpKZWVlWzdupXXXnutIQybs2nTJioqKqiqquKll15i48aNDcumT5/Oxo0b2bJlC5dffjk//vGPGT9+PFOmTOHRRx+lqqqKSy+9tKF9bW0txcXFrFixgm3btlFXV8eyZcsalvfu3ZvNmzczZ86cNod16i+zu3XrVn74wx9y5513AjRcZreqqor169eTkZHBL3/5S66//nqqqqrYsmVLXK7KqEAXkWbtnbuXO4bfQWZa5AJdmWmZFI0oYt8D+zrUb+Nhl8bDLc8++yyjR48mLy+P7du3nzE80tT69euZNm0amZmZ9OzZkylTpjQse+utt7j66qsZMWIE5eXlbN++vdV6du/ezeDBg7nssssAuOuuu1i3bl3D8unTpwOQn5/fcEGvlmzYsIGvfe1rQPOX2X388cf56KOPSEtLY8yYMTz99NMsWrSIbdu20aNHj1b7joUCXUSa1a9HP3p270nt6VrS09KpPV1Lz+496ZvVt0P9Tp06ldWrV7N582ZOnDhBfn4++/btY8mSJaxevZqtW7cyefLkFi+b25bi4mKeeOIJtm3bxsKFC8+5n3r1l+DtyOV3O+syuwp0EWnR4b8cpiS/hDfufoOS/JK4HBjNysri2muvZdasWQ1758ePH+f888/nggsu4PDhww1DMi2ZMGECK1eu5OTJk9TU1PDiiy82LKupqaFfv36cOnWq4ZK3AD169KCmpuasvoYOHcr+/fvZs2cPAD//+c+55pprzul3S/ZldnUtFxFp0Qu3v9Bwf+nkpXHrd+bMmUybNq1h6KX+crPDhg1jwIABFBYWtvr40aNHc/vttzNq1CguuugixowZ07DskUceYdy4cfTp04dx48Y1hPiMGTO45557ePzxxxsOhgKkp6fz9NNPc9ttt1FXV8eYMWMoKSk5p9+r/rtOR44cSWZm5hmX2V2zZg1dunThyiuv5IYbbqCiooJHH32Ubt26kZWVFZc9dF0+V+QzRJfPDZaEXD7XzCaZ2W4z22Nm85tZPsjMVpvZVjNba2bZzfUjIiKJ02agm1lXYClwA3AFMNPMrmjSbAnwM3cfCSwG/inehYqISOti2UMfC+xx973u/glQAUxt0uYK4NXo/TXNLBeRFJGsYVZpn3PZTrEEen/g3UbT1dF5jW0BpkfvTwN6mFmvph2Z2WwzqzSzyiNHjrS7WBHpmPT0dI4ePapQT3HuztGjR0lPT2/X4+J1lsu3gSfMrBhYB7wHnG7ayN3LgDKIHBSN07pFJEbZ2dlUV1ejHarUl56eTnZ2+w5HxhLo7wEDGk1nR+c1cPf3ie6hm1kWcIu7n31JNBFJqm7dujF48OBklyEJEsuQy0ZgiJkNNrPzgBnAqsYNzKy3mdX39RDwk/iWKSIibWkz0N29DrgfeBnYCTzr7tvNbLGZ1V9AYSKw28z+CFwMlCaoXhERaYE+WCQiEiAd/mCRiIikPgW6iEhIKNBFREJCgS4iEhIKdBGRkFCgi4iEhAJdRCQkFOgiIiGhQBcRCQkFuohISCjQRURCQoEuIhISCnQRkZBQoIuIhIQCXUQkJBToIiIhoUAXEQkJBbqISEgo0EVEQkKBLiISEgp0EZGQUKCLiISEAl1EJCQU6CIiIaFAFxEJCQW6iEhIKNBFREJCgS4iEhIKdBGRkFCgi4iEhAJdRCQkFOgiIiGhQBcRCYmYAt3MJpnZbjPbY2bzm1k+0MzWmNmbZrbVzG6Mf6kiItKaNgPdzLoCS4EbgCuAmWZ2RZNm/xt41t3zgBnAk/EuVEREWhfLHvpYYI+773X3T4AKYGqTNg70jN6/AHg/fiWKiEgsYgn0/sC7jaaro/MaWwT8g5lVAy8B32iuIzObbWaVZlZ55MiRcyhXRERaEq+DojOB5e6eDdwI/NzMzurb3cvcvcDdC/r06ROnVYuICMQW6O8BAxpNZ0fnNXY38CyAu/8eSAd6x6NAERGJTSyBvhEYYmaDzew8Igc9VzVpcxD4EoCZXU4k0DWmIiLSidoMdHevA+4HXgZ2EjmbZbuZLTazKdFm3wLuMbMtwDNAsbt7oooWEZGzpcXSyN1fInKws/G8hxvd3wEUxrc0ERFpD31SVEQkJBToIiIhoUAXEQkJBbqISEgo0EVEQkKBLiISEgp0EZGQUKCLiISEAl1EJCQU6CIiIaFAFxEJCQW6iEhIKNBFREJCgS4iEhIKdBGRkFCgi4iEhAJdRCQkFOgiIiGhQBcRCQkFuohISCjQRURCQoEuIhISCnQRkZBQoIuIhIQCXUQkJBToIiIhoUAXEQkJBbqISEgo0EVEQkKBLiISEgp0EZGQUKCLiISEAh2gvBxycqBLl8jP8vJkVyQi0m5pyS4g6crLYfZsOHEiMn3gQGQaoKgoeXWJiLRTTHvoZjbJzHab2R4zm9/M8n8zs6ro7Y9m9lH8S02QBQv+Fub1TpyIzBcRCZA299DNrCuwFPgKUA1sNLNV7r6jvo27z2vU/htAXgJqTYyDB9s3X0QkRcWyhz4W2OPue939E6ACmNpK+5nAM/EorlMMHNi++SIiKSqWQO8PvNtoujo67yxmNggYDLzawvLZZlZpZpVHjhxpb62JUVoKmZlnzsvMjMwXEQmQeJ/lMgN4zt1PN7fQ3cvcvcDdC/r06RPnVZ+joiIoK4NBg8As8rOsTAdERSRwYjnL5T1gQKPp7Oi85swA7utoUZ2uqEgBLiKBF8se+kZgiJkNNrPziIT2qqaNzGwY8HfA7+NbooiIxKLNQHf3OuB+4GVgJ/Csu283s8VmNqVR0xlAhbt7YkoVEZHWxDSG7u4vuftl7n6pu5dG5z3s7qsatVnk7medo/6ZlqhPoCai3yDVmqh+g1Rr0PoNUq2JlOh63T0pt/z8fA+1X/zCPTPTHf52y8yMzE+1foNUa6L6DVKtQes3SLU27nvQIHezyM949RmHeoFKbyFXFeiJMmjQmRuu/jZoUOr1G6RaE9VvkGoNWr9BqtU9cW8Ucaq3tUC3yPLOV1BQ4JWVlUlZd6fo0iWyuZoyg08/Ta1+g1RrovoNUq1B6zdItUJkKOTAgbPnDxoE+/efe79xqtfMNrl7QbOrOOfipHWJ+gRqIvoNUq2J6jdItQat3yDVCom7HEhnfCq9pV33RN9CP+QSpHHDINWaqH6DVGvQ+g1Sre4pP5SDxtCTJBEHVhLVb5BqTVS/Qao1aP0GrdYUPtjaWqBrDF1EpKny8sgltA8ejAyJlJamzKfJWxtD1xdciIg0FdDLgeigqIhISCjQRURCQoEuIhISCnQRkZBQoIuIhIQCXUQkJBToIiIhoUAXEQkJBbqISEgo0EVEQkKBLiISEgp0EZGQUKCLiISEAl1EJCQU6CIiIaFAFxEJCQW6iEhIKNBFREJCgS4iEhIKdBGRkFCgi4iEhAJdRCQkFOgiIiGhQBcRCQkFuohISCjQRURCIqZAN7NJZrbbzPaY2fwW2nzVzHaY2XYz+2V8yxQRkbaktdXAzLoCS4GvANXARjNb5e47GrUZAjwEFLr7/5jZRYkqWEREmhfLHvpYYI+773X3T4AKYGqTNvcAS939fwDc/U/xLVNERNoSS6D3B95tNF0dndfYZcBlZvY7M3vDzCY115GZzTazSjOrPHLkyLlVLCIizYrXQdE0YAgwEZgJ/MjMLmzayN3L3L3A3Qv69OkTp1WLiAjEFujvAQMaTWdH5zVWDaxy91Puvg/4I5GAFxGRThJLoG8EhpjZYDM7D5gBrGrSZiWRvXPMrDeRIZi9caxTRETa0Gagu3sdcD/wMrATeNbdt5vZYjObEm32MnDUzHYAa4DvuPvRRBUtIiJnM3dPyooLCgq8srIyKesWEQkqM9vk7gXNLdMnRUVEQkKBLiISEgp0EZGQUKCLiISEAl1EJCQCF+iHag5xzfJr+ODjD5JdiohISglcoD+y7hE2HNzA4tcWJ7sUEZGUEpjz0DNKM6itqz1rfnpaOicXnIxnaSIiKSsU56HvnbuXO4bfQWZaJgCZaZkUjShi3wP7klyZiEhqCEyg9+vRj57de1J7upb0tHRqT9fSs3tP+mb1TXZpIiIpITCBDnD4L4cpyS/hjbvfoCS/RAdGRUQaCcwYuoiIhGQMXUREWqdAFxEJCQW6iEhIKNBFREJCgS4iEhIKdBGRkFCgi4iEhAJdRCQkFOgiIiGhQBcRCQkFuohISCjQRURCQoEuIhISCnQRkZBQoIuIhIQCXUQkJBToIiIhoUAPqEM1h7hm+TX6Gj4RaaBAT7BEBe8j6x5hw8ENLH5tcVz7/axL1PbSG3DwBHGbKdCjghK8GaUZ2A+MZZXL+NQ/ZVnlMuwHRkZpRlz6D5JEbLNEvVHqDThxgvLa7Qz6kuiof/zVP/Lvm/6de/Pv5cnJT3a4v4zSDGrras+an56WzskFJ8+530M1h/j2b77Nyl0rOVF3gsy0TKZdPo0lf7+Evll9O1JywhyqOcSM52ew4tYVca0xntssUdsrUf0mWiK2WRCeB5D626zDXxJtZpPMbLeZ7TGz+c0sLzazI2ZWFb19vaNFd5ZE7fHunbuXO4bfQWZaJgCZaZkUjShi3wP7OtRvvx796Nm9J7Wna0lPS6f2dC09u/eMywskKHs6idhmidpeieq3XlC2WSL6DNprtzO0Gehm1hVYCtwAXAHMNLMrmmm6wt1zo7en4lxnwgQxeA//5TAl+SW8cfcblOSXxO3F/Fl+wSVqeyXyeQDB2GZBeh5A4rdZIsfmY9lDHwvscfe97v4JUAFMjXslSRLE4H3h9hdYOnkpo/qOYunkpbxw+wsd6k8vuIhEba9E9BukbRa05wEk7rkAiR2bT4uhTX/g3UbT1cC4ZtrdYmYTgD8C89z93aYNzGw2MBtg4MCB7a82Qeo33uz82ZRtKuPQx4fi0m/joF06eWlc+kyEvXP3tjgu3xGd8YKL5zZL1PZKRL9B2mZBex5AYrZZ07H5ZZXLWFa5LK5j87EEeixeBJ5x97+a2b3AT4HrmjZy9zKgDCIHReO07g4LSvAmil5wwRO0babnQeLehBuLJdDfAwY0ms6Ozmvg7kcbTT4F/EvHS5POpBdc8ARpm+l5kPixeYjhtEUzSyMyjPIlIkG+EbjD3bc3atPP3Q9F708DvuvuV7XWb6qdtigikmjTV0ynX1a/M96E23sMrLXTFtvcQ3f3OjO7H3gZ6Ar8xN23m9lioNLdVwFzzWwKUAf8GShuV4UiIp8Bif5PRR8sEhEJkA5/sEhERFKfAl1EJCQU6CIiIaFAFxEJCQW6iEhIJO0sFzM7AhxIyspb1hv4MNlFtEOQ6lWtiROkeoNUK6RmvYPcvU9zC5IW6KnIzCpbOh0oFQWpXtWaOEGqN0i1QvDq1ZCLiEhIKNBFREJCgX6msmQX0E5Bqle1Jk6Q6g1SrRCwejWGLiISEtpDFxEJCQW6iEhIKNABMxtgZmvMbIeZbTezB5JdU1vMrKuZvWlm/5XsWtpiZhea2XNmtsvMdprZF5JdU0vMbF70OfCWmT1jZunJrqkxM/uJmf3JzN5qNO9zZvZbM3s7+vPvklljvRZqfTT6PNhqZv9hZhcms8bGmqu30bJvmZmbWe9k1BYrBXpEHfAtd78CuAq4z8yuSHJNbXkA2JnsImL0f4D/dvdhwChStG4z6w/MBQrcfTiR6//PSG5VZ1kOTGoybz6w2t2HAKuj06lgOWfX+ltguLuPJPLFOQ91dlGtWM7Z9WJmA4C/Bw52dkHtpUAH3P2Qu2+O3q8hEjj9k1tVy8wsG5hM5Ov+UpqZXQBMAH4M4O6fuPtHya2qVWlARvSbujKB95NczxncfR2RL5FpbCqR7/El+vPmTi2qBc3V6u6/cfe66OQbRL7SMiW08LcF+DfgQSDlzyBRoDdhZjlAHvD/kltJqx4j8gT7NNmFxGAwcAR4OjpE9JSZnZ/soprj7u8BS4jsiR0Cjrn7b5JbVUwurv8KSOAD4OJkFtMOs4BfJ7uI1pjZVOA9d9+S7FpioUBvxMyygOeB/+Xux5NdT3PM7CbgT+6+Kdm1xCgNGA0sc/c84C+kzpDAGaJjz1OJvAl9HjjfzP4huVW1j0fOQ075PUkzW0BkqLM82bW0xMwyge8BDye7llgp0KPMrBuRMC939/Z9a2vnKgSmmNl+oAK4zsx+kdySWlUNVLt7/X88zxEJ+FT0ZWCfux9x91PAC8D4JNcUi8Nm1g8iX9gO/CnJ9bTKzIqBm4AiT+0PwlxK5M19S/T1lg1sNrO+Sa2qFQp0wMyMyBjvTnf/12TX0xp3f8jds909h8gBu1fdPWX3It39A+BdMxsanfUlYEcSS2rNQeAqM8uMPie+RIoewG1iFXBX9P5dwH8msZZWmdkkIsOFU9z9RLLraY27b3P3i9w9J/p6qwZGR5/TKUmBHlEIfI3I3m5V9HZjsosKkW8A5Wa2FcgFfpjkepoV/S/iOWAzsI3I6yOlPvptZs8AvweGmlm1md0N/DPwFTN7m8h/Gf+czBrrtVDrE0AP4LfR19n/TWqRjbRQb6Doo/8iIiGhPXQRkZBQoIuIhIQCXUQkJBToIiIhoUAXEQkJBbqISEgo0EVEQuL/A1EctwN/JFNCAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = list(range(1, num_epochs+1))\n",
        "plt.plot(epochs, train_losses, 'ro', label=\"Training loss\")\n",
        "plt.plot(epochs, valid_losses, 'g*', label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb-9yhx_MWR0"
      },
      "source": [
        "**Testing the model's accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "P_YQEvKQMXIz",
        "outputId": "55ebf2fc-b6dd-4dd0-c88d-89be5dd03669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model based on 28 test samples: 28.571428571428573\n"
          ]
        }
      ],
      "source": [
        "with torch.set_grad_enabled(False):\n",
        "    accuracy = 0.0\n",
        "    for features, label in test_iterator:\n",
        "      # transfer to GPU\n",
        "      features = torch.concat(features).to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      output = four_layer_nn2(features.float())\n",
        "\n",
        "      predicted = torch.round(output)\n",
        "      accuracy += (predicted == label).sum().item()\n",
        "\n",
        "    print(\"Accuracy of the model based on \" + str(len(test_iterator)) + \" test samples: \" + str(100 * accuracy/len(test_iterator)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OGdE1Y2qG16"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "This perceptron performed approximately the same as the first four-layer one. Here, the change in loss function did not make a different, because the main issue was that the network is too complex and did not manage to learn anything from provided input data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ameZIgo_9TKe"
      },
      "source": [
        "## Five-layer perceptron\n",
        "\n",
        "Input layer -> hidden layer -> hidden layer -> hidden layer -> hidden layer -> output layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U1QklbmBU9C"
      },
      "source": [
        "**Trained with Mean Squared Error loss function:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5QvuSDXOY0Wm",
        "outputId": "6dd4af09-e7d0-4d2c-8b28-c9b9527e911a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultilayerPerceptron(\n",
            "  (input_layer): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (1): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (2): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (3): Linear(in_features=3, out_features=3, bias=True)\n",
            "  )\n",
            "  (output_layer): Linear(in_features=3, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Training the five-layer perceptron with MSE loss...\n",
            "\n",
            "Starting epoch 1...\n",
            "Training loss = 0.7710545982595411\n",
            "Validation loss = 0.47420517131686213\n",
            "Starting epoch 2...\n",
            "Training loss = 0.6876925140625028\n",
            "Validation loss = 0.4820632547372952\n",
            "Starting epoch 3...\n",
            "Training loss = 0.6870002369872898\n",
            "Validation loss = 0.4826560513873119\n",
            "Starting epoch 4...\n",
            "Training loss = 0.686823011810426\n",
            "Validation loss = 0.48310286850319245\n",
            "Starting epoch 5...\n",
            "Training loss = 0.6866575004525137\n",
            "Validation loss = 0.4835417335329112\n",
            "Starting epoch 6...\n",
            "Training loss = 0.6864947869375035\n",
            "Validation loss = 0.4839751890685875\n",
            "Starting epoch 7...\n",
            "Training loss = 0.6863346476290774\n",
            "Validation loss = 0.48440346339484674\n",
            "Starting epoch 8...\n",
            "Training loss = 0.6861770417584532\n",
            "Validation loss = 0.4848263919528108\n",
            "Starting epoch 9...\n",
            "Training loss = 0.6860219257783099\n",
            "Validation loss = 0.4852442979288753\n",
            "Starting epoch 10...\n",
            "Training loss = 0.685869258491266\n",
            "Validation loss = 0.48565694977878593\n",
            "Starting epoch 11...\n",
            "Training loss = 0.6857189719777514\n",
            "Validation loss = 0.48606454802793453\n",
            "Starting epoch 12...\n",
            "Training loss = 0.6855710929140904\n",
            "Validation loss = 0.48646703202975916\n",
            "Starting epoch 13...\n",
            "Training loss = 0.6854255161809826\n",
            "Validation loss = 0.48686450302484446\n",
            "Starting epoch 14...\n",
            "Training loss = 0.6852822592310466\n",
            "Validation loss = 0.4872568446182413\n",
            "Starting epoch 15...\n",
            "Training loss = 0.6851412747385959\n",
            "Validation loss = 0.4876441593893105\n"
          ]
        }
      ],
      "source": [
        "# initialize the NN to have 4 hidden layers\n",
        "five_layer_nn1 = MultilayerPerceptron(4, 4, 3, 1)\n",
        "print(five_layer_nn1)\n",
        "\n",
        "# transfer model to GPU\n",
        "five_layer_nn1.to(device)\n",
        "\n",
        "# define loss function and optimizer (stochastic gradient descent)\n",
        "loss_function = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(five_layer_nn1.parameters(), lr=0.01)\n",
        "\n",
        "print(\"\\nTraining the five-layer perceptron with MSE loss...\\n\")\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "# loop over epochs\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Starting epoch \" + str(epoch + 1) + \"...\")\n",
        "  train_loss = 0.0\n",
        "\n",
        "  # training\n",
        "  for features, label in train_iterator:\n",
        "    # transfer to GPU\n",
        "    features = torch.concat(features).to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # model computations\n",
        "\n",
        "    # set gradients to 0 before calculating loss\n",
        "    five_layer_nn1.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    output = five_layer_nn1(features.float())\n",
        "\n",
        "    loss = loss_function(output, label.float())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  print(\"Training loss = \" + str(train_loss/len(train_iterator)))\n",
        "  train_losses.append(train_loss/len(train_iterator))\n",
        "\n",
        "  # validation\n",
        "  with torch.set_grad_enabled(False):\n",
        "    valid_loss = 0.0\n",
        "    for features, label in validation_iterator:\n",
        "      # transfer to GPU\n",
        "      features = torch.concat(features).to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      # model computations\n",
        "      output = five_layer_nn1(features.float())\n",
        "      loss = loss_function(output, label.float())\n",
        "\n",
        "      valid_loss += loss.item()\n",
        "\n",
        "    print(\"Validation loss = \" + str(valid_loss/len(validation_iterator)))\n",
        "    valid_losses.append(valid_loss/len(validation_iterator))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq3h5Jba8Yo9"
      },
      "source": [
        "**Plot the training-validation curve**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "i07bBxSF8ZWc",
        "outputId": "09430850-28de-4cd7-b76a-2b029f6e9175"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = list(range(1, num_epochs+1))\n",
        "plt.plot(epochs, train_losses, 'ro', label=\"Training loss\")\n",
        "plt.plot(epochs, valid_losses, 'g*', label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECWE6oMsMZAV"
      },
      "source": [
        "**Testing the model's accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "luuswmJdMZio",
        "outputId": "aed61bb4-5ac1-4014-8ea3-0c832d11fdba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model based on 28 test samples: 28.571428571428573\n"
          ]
        }
      ],
      "source": [
        "with torch.set_grad_enabled(False):\n",
        "    accuracy = 0.0\n",
        "    for features, label in test_iterator:\n",
        "      # transfer to GPU\n",
        "      features = torch.concat(features).to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      output = five_layer_nn1(features.float())\n",
        "\n",
        "      predicted = torch.round(output)\n",
        "      accuracy += (predicted == label).sum().item()\n",
        "\n",
        "    print(\"Accuracy of the model based on \" + str(len(test_iterator)) + \" test samples: \" + str(100 * accuracy/len(test_iterator)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLaeGvStBk_W"
      },
      "source": [
        "**Trained with Mean Absolute Error loss function:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OwIItla62B2O",
        "outputId": "4a5de4c9-b5e3-460e-d46f-a61da5238cdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultilayerPerceptron(\n",
            "  (input_layer): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (1): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (2): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (3): Linear(in_features=3, out_features=3, bias=True)\n",
            "  )\n",
            "  (output_layer): Linear(in_features=3, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Training the five-layer perceptron with MAE loss...\n",
            "\n",
            "Starting epoch 1...\n",
            "Training loss = 1.0450096257929025\n",
            "Validation loss = 0.6383118271827698\n",
            "Starting epoch 2...\n",
            "Training loss = 0.8598983311759574\n",
            "Validation loss = 0.5503119230270386\n",
            "Starting epoch 3...\n",
            "Training loss = 0.7028342229979379\n",
            "Validation loss = 0.5023119688034058\n",
            "Starting epoch 4...\n",
            "Training loss = 0.6746428523744855\n",
            "Validation loss = 0.5023119688034058\n",
            "Starting epoch 5...\n",
            "Training loss = 0.6746428523744855\n",
            "Validation loss = 0.5023119688034058\n",
            "Starting epoch 6...\n",
            "Training loss = 0.6746428523744855\n",
            "Validation loss = 0.5023119688034058\n",
            "Starting epoch 7...\n",
            "Training loss = 0.6746428523744855\n",
            "Validation loss = 0.5023119688034058\n",
            "Starting epoch 8...\n",
            "Training loss = 0.6746428523744855\n",
            "Validation loss = 0.5023119688034058\n",
            "Starting epoch 9...\n",
            "Training loss = 0.6746428523744855\n",
            "Validation loss = 0.5023119688034058\n",
            "Starting epoch 10...\n",
            "Training loss = 0.6746428523744855\n",
            "Validation loss = 0.5023119688034058\n",
            "Starting epoch 11...\n",
            "Training loss = 0.6746428523744855\n",
            "Validation loss = 0.5023119688034058\n",
            "Starting epoch 12...\n",
            "Training loss = 0.6746428523744855\n",
            "Validation loss = 0.5023119688034058\n",
            "Starting epoch 13...\n",
            "Training loss = 0.6746428523744855\n",
            "Validation loss = 0.5023119688034058\n",
            "Starting epoch 14...\n",
            "Training loss = 0.6746428523744855\n",
            "Validation loss = 0.5023119688034058\n",
            "Starting epoch 15...\n",
            "Training loss = 0.6746428523744855\n",
            "Validation loss = 0.5023119688034058\n"
          ]
        }
      ],
      "source": [
        "# initialize the NN to have 4 hidden layers\n",
        "five_layer_nn2 = MultilayerPerceptron(4, 4, 3, 1)\n",
        "print(five_layer_nn2)\n",
        "\n",
        "# transfer model to GPU\n",
        "five_layer_nn2.to(device)\n",
        "\n",
        "# define loss function and optimizer (stochastic gradient descent)\n",
        "loss_function = torch.nn.L1Loss()\n",
        "optimizer = torch.optim.SGD(five_layer_nn2.parameters(), lr=0.01)\n",
        "\n",
        "print(\"\\nTraining the five-layer perceptron with MAE loss...\\n\")\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "# loop over epochs\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Starting epoch \" + str(epoch + 1) + \"...\")\n",
        "  train_loss = 0.0\n",
        "\n",
        "  # training\n",
        "  for features, label in train_iterator:\n",
        "    # transfer to GPU\n",
        "    features = torch.concat(features).to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # model computations\n",
        "\n",
        "    # set gradients to 0 before calculating loss\n",
        "    five_layer_nn2.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    output = five_layer_nn2(features.float())\n",
        "\n",
        "    loss = loss_function(output, label.float())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  print(\"Training loss = \" + str(train_loss/len(train_iterator)))\n",
        "  train_losses.append(train_loss/len(train_iterator))\n",
        "\n",
        "  # validation\n",
        "  with torch.set_grad_enabled(False):\n",
        "    valid_loss = 0.0\n",
        "    for features, label in validation_iterator:\n",
        "      # transfer to GPU\n",
        "      features = torch.concat(features).to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      # model computations\n",
        "      output = five_layer_nn2(features.float())\n",
        "      loss = loss_function(output, label.float())\n",
        "\n",
        "      valid_loss += loss.item()\n",
        "\n",
        "    print(\"Validation loss = \" + str(valid_loss/len(validation_iterator)))\n",
        "    valid_losses.append(valid_loss/len(validation_iterator))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnoG3kaF8bqS"
      },
      "source": [
        "**Plot the training-validation curve**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "c_WL8bYV8cRK",
        "outputId": "48a8c48a-2b13-459e-ffab-76c582f21d19"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = list(range(1, num_epochs+1))\n",
        "plt.plot(epochs, train_losses, 'ro', label=\"Training loss\")\n",
        "plt.plot(epochs, valid_losses, 'g*', label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1fUO4orMb3A"
      },
      "source": [
        "**Testing the model's accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "V1BVnHnxMcj_",
        "outputId": "b68ab641-374b-4739-c2a7-4bbad19f6ab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model based on 28 test samples: 28.571428571428573\n"
          ]
        }
      ],
      "source": [
        "with torch.set_grad_enabled(False):\n",
        "    accuracy = 0.0\n",
        "    for features, label in test_iterator:\n",
        "      # transfer to GPU\n",
        "      features = torch.concat(features).to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      output = five_layer_nn2(features.float())\n",
        "\n",
        "      predicted = torch.round(output)\n",
        "      accuracy += (predicted == label).sum().item()\n",
        "\n",
        "    print(\"Accuracy of the model based on \" + str(len(test_iterator)) + \" test samples: \" + str(100 * accuracy/len(test_iterator)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbCNzmhuq44o"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "Same as in four-layer perceptrons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_Y-mi6Prk39"
      },
      "source": [
        "# Final conclusions\n",
        "\n",
        "We have tested neural networks with different numbers of hidden layers in them. In general, it seems that the smaller nets perform better in this particular task.\n",
        "\n",
        "Validation during training allows us to see how well the network generalizes the problem - so how it performs on new samples which were not analyzed by the model before. It seems that smaller nets (with 1 or 2 hidden layers) have managed to generalize well.\n",
        "\n",
        "On the other hand, larger nets did not seem to grasp the problem effectively. The networks with more than 4 layers (so more than 3 hidden layers) predict the same value for all samples and thus their accuracies are very low (unless the test data is not balanced and happens to have majority of samples belonging to the class which is the closest to the model's assumed prediction value).\n",
        "\n",
        "**Effects of the number of perceptron layers on final metrics depend on the problem complexity.** In our case, the provided data was really incomplex - there were only 4 input features and 112 training samples, so there was no space for the large models to deeply study the data. **Networks with more layers were too complex for this incomplex task.** However, if we had a very complex dataset with lots of intricate details and differences - a deeper network given more time to train would probably accomplish very satisfactory results."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "EARIN_task5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
